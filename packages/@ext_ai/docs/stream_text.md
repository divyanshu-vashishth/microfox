## Function: `streamText`

Streams text generations from a language model. This function is ideal for interactive applications like chatbots and real-time text generation, allowing you to process and display text as it's generated by the model. It also supports tool calling for enhanced functionality.

**Purpose:**

Enables streaming text generation from language models, facilitating interactive experiences and real-time applications.

**Parameters:**

- `model`: **LanguageModel** (required)
    - The language model to use for text generation.  Example: `openai('gpt-4-turbo')`.  This parameter expects a LanguageModel object, which is typically created using provider-specific functions like `openai()`.
- `system` (optional): **string**
    - The system-level instruction that sets the behavior of the model. This prompt guides the overall tone and style of the generated text.
- `prompt` (optional): **string**
    - The input prompt that triggers the text generation. This is the specific text or question you want the model to respond to.
- `messages` (optional): **array<CoreSystemMessage | CoreUserMessage | CoreAssistantMessage | CoreToolMessage> | array<UIMessage>**
    - An array of messages representing a conversation history. This allows for context-aware responses.  Automatically converts UI messages from the `useChat` hook.  Each message object can be one of the following types:
        - `CoreSystemMessage`:
            - `role`: **string** - Always 'system'.
            - `content`: **string** - The system message content.
        - `CoreUserMessage`:
            - `role`: **string** - Always 'user'.
            - `content`: **string | array<TextPart | ImagePart | FilePart>** - The user message content.
                - `TextPart`:
                    - `type`: **string** - Always 'text'.
                    - `text`: **string** - The text content.
                - `ImagePart`:
                    - `type`: **string** - Always 'image'.
                    - `image`: **string | Uint8Array | Buffer | ArrayBuffer | URL** - The image data. Strings can be base64 encoded content, base64 data URLs, or http(s) URLs.
                    - `mimeType`: **string** (optional) - The MIME type of the image.
                - `FilePart`:
                    - `type`: **string** - Always 'file'.
                    - `data`: **string | Uint8Array | Buffer | ArrayBuffer | URL** - The file data. Strings can be base64 encoded content, base64 data URLs, or http(s) URLs.
                    - `mimeType`: **string** - The MIME type of the file.
        - `CoreAssistantMessage`:
            - `role`: **string** - Always 'assistant'.
            - `content`: **string | array<TextPart | ReasoningPart | RedactedReasoningPart | ToolCallPart>** - The assistant message content.
                - `TextPart`: As described above.
                - `ReasoningPart`:
                    - `type`: **string** - Always 'reasoning'.
                    - `text`: **string** - The reasoning text.
                    - `signature`: **string** (optional) - The signature for the reasoning.
                - `RedactedReasoningPart`:
                    - `type`: **string** - Always 'redacted-reasoning'.
                    - `data`: **string** - The redacted data.
                - `ToolCallPart`:
                    - `type`: **string** - Always 'tool-call'.
                    - `toolCallId`: **string** - The ID of the tool call.
                    - `toolName`: **string** - The name of the tool.
                    - `args`: **object** - Arguments for the tool call (based on the tool's Zod schema).
        - `CoreToolMessage`:
            - `role`: **string** - Always 'tool'.
            - `content`: **array<ToolResultPart>** - The tool result content.
                - `ToolResultPart`:
                    - `type`: **string** - Always 'tool-result'.
                    - `toolCallId`: **string** - The ID of the tool call.
                    - `toolName`: **string** - The name of the tool.
                    - `result`: **unknown** - The result returned by the tool.
                    - `isError`: **boolean** (optional) - Indicates if the result is an error.
- `tools` (optional): **ToolSet**
    - A set of tools that the model can access and call during text generation.  Each tool is defined as:
        - `description` (optional): **string** - A description of the tool's purpose and usage.
        - `parameters`: **Zod Schema | JSON Schema** - The schema defining the tool's input parameters.
        - `execute` (optional): **(parameters: T, options: ToolExecutionOptions) => Promise<RESULT>** - An asynchronous function that executes the tool with the given parameters.
            - `options`: **ToolExecutionOptions**
                - `toolCallId`: **string** - The ID of the tool call.
                - `messages`: **array<CoreMessage>** - Messages related to the tool call.
                - `abortSignal`: **AbortSignal** - An optional abort signal.
-  Many other optional parameters exist, including `toolChoice`, `maxTokens`, `temperature`, `topP`, `topK`, `presencePenalty`, `frequencyPenalty`, `stopSequences`, `seed`, `maxRetries`, `abortSignal`, `headers`, `maxSteps`, `experimental_generateMessageId`, `experimental_continueSteps`, `experimental_telemetry`, `toolCallStreaming`, `experimental_transform`, `experimental_repairToolCall`, `onChunk`, `onError`, `experimental_output`, `onStepFinish`, and `onFinish`.  These parameters offer fine-grained control over the text generation process, including tool selection, token limits, sampling parameters, stopping conditions, error handling, and streaming behavior.  Refer to the provided documentation for detailed explanations of each parameter.

**Return Value:**

An object containing the following properties:

- `textStream`: **AsyncIterable<string> & ReadableStream<string>** - A stream of generated text deltas.
- `fullStream`: **AsyncIterable<TextStreamPart> & ReadableStream<TextStreamPart>** - A stream of all events, including text deltas, tool calls, and tool results.
- Several promise-based properties that resolve when the generation is complete: `finishReason`, `usage`, `providerMetadata`, `text`, `reasoning`, `reasoningDetails`, `sources`, `files`, `toolCalls`, `toolResults`, `request`, `response`, `steps`.  These provide comprehensive information about the generation process and results.
- Helper functions for stream management and response handling: `consumeStream`, `pipeDataStreamToResponse`, `pipeTextStreamToResponse`, `toDataStream`, `toDataStreamResponse`, `toTextStreamResponse`, `mergeIntoDataStream`.

**Examples:**

```typescript
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

// Example 1: Basic usage
const { textStream } = streamText({
  model: openai('gpt-4-turbo'),
  prompt: 'Write a short story about a robot learning to love.'
});

for await (const textPart of textStream) {
  process.stdout.write(textPart);
}


// Example 2: Using system prompt and messages
const { fullStream } = streamText({
  model: openai('gpt-3.5-turbo'),
  system: 'You are a helpful assistant.',
  messages: [
    { role: 'user', content: 'What is the capital of France?' },
    { role: 'assistant', content: 'Paris.' },
    { role: 'user', content: 'And what is its population?' }
  ]
});

for await (const part of fullStream) {
  if (part.type === 'text-delta') {
    process.stdout.write(part.textDelta);
  }
}


// Example 3: Tool calling (requires defining and registering tools)
// ... (Tool definition and registration not shown here) ...

const { textStream, toolResults } = streamText({
  model: openai('gpt-4-turbo'),
  prompt: 'What is the weather in London?',
  tools: {
    getWeather: {
      description: 'Gets the current weather in a given location.',
      parameters: /* ... Zod schema for location ... */,
      execute: async (parameters) => { /* ... fetch weather data ... */ }
    }
  }
});

// ... (Process textStream and toolResults) ...
```
